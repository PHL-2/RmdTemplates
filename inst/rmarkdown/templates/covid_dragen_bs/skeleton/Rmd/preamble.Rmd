
```{r libraries, message=FALSE, warning=FALSE}
library(here)
library(tidyverse)
library(rvest)
library(pander)
library(kableExtra)
library(ggsci)
library(RColorBrewer)
library(patchwork)

```

```{r functions}

#this file needs to sit in a [aux_files/functions] directory path above this project directory
tryCatch(
  {
    source(gsub(basename(here()), "aux_files/functions/R_all_functions_v3.R", here()))
  },
  error = function(e) {
  stop (simpleError("The R_all_functions_v3.R file needs to sit in a [aux_files/functions] directory path above this project directory"))
  }
)

```

```{r versions and dates manual inputs}

#if these variables are missing, throw an error

# YYYY-MM-DD
date_pipeline_was_run <- ""

# N.N.N
dragen_covid_lineage_version <- ""

# N.N.N
nextclade_version <- ""

primer_select <-  # set variable as 1 for V3, 2 for V4, or 3 for V4.1

artic_primer_scheme <- c("V3", "V4", "V4.1")[primer_select]
bs_bed_file_used <- c("nCov-2019.bed", "artic_V4_primer_scheme_NC_045512.2.bed", "artic_v4.1_primers_nc045512.2.bed")[primer_select]

# minimum acceptable number of reads
min_reads <- 10000
```

```{r file paths}

### mapping file path
#try to get it automagically
mapping_file_fp <- here("metadata", list.files(here("metadata"), pattern = ".tsv|.csv"))

### bcl2fastq info; right now, running GenerateFASTQ module on the MiSeq machine to generate fastq files. Use these files later, when switching to bcl2fastq
#b2fq_c_fp <- here("Data", "bcl2fastq", "commands.tsv")
#b2fq_v_fp <- here("Data", "bcl2fastq", "bcl2fastqVersion.stderr.txt")

### demultiplexing results from BaseSpace
gen_fq_fp <- here("Data", "demux_reads", "CompletedJobInfo.xml")
adaptertrimming_fp <- here("Data", "demux_reads", "AdapterTrimming.txt")
#demuxsum_fp <- here("Data", "demux_reads", "DemuxSummaryF1L1.txt")
demuxsum_fp <- here("Data", "demux_reads", "DemultiplexSummaryF1L1.txt")
fastqsum_fp <- here("Data", "demux_reads", "FastqSummaryF1L1.txt")
SampleSheet_fp <- here("Data", "demux_reads", "SampleSheetused.csv")

### kmer fp
kmer_fp <- here("Data", "kmer", "Data export.csv")

### NextClade results fp
nextclade_fp = here("Data", "NextClade", "Data export.csv")

### Pangolin
pangolin_fp <- here("Data", "Pangolin", "Data export.csv")

```

```{r load bcl2fq, eval = FALSE}

bcl2fq_version <- read_delim(b2fq_v_fp, skip = 1, col_names = FALSE) %>%
  slice(1) %>%
  select(X2) %>%
  pull()

#just reading in command file as one column
bcl2fq_flags <- read_delim(b2fq_c_fp, col_names = FALSE, col_types = cols(.default = "c"), delim = ";") %>%
  slice(1) %>%
  mutate(X1 = gsub("^.*bcl2fastq", "bcl2fastq", X1)) %>%
  mutate(X1 = gsub(" --", "\n\t--", X1)) %>%
  mutate(X1 = gsub(" -", "\n\t-", X1)) %>%
  pull()

```

```{r load GenerateFASTQ module}

JobCompletedInfo <- xml2::read_xml(gen_fq_fp)

workflow_name <- JobCompletedInfo %>%
  html_elements("Analysis") %>%
  html_text2()

gen_fq_version <- JobCompletedInfo %>%
  html_elements("WorkflowVersion") %>%
  html_text2()

```

```{r load read numbers}

trimmin <- read_delim(adaptertrimming_fp) %>%
  filter(!is.na(TrimmedBases))

# read counts by sample number
fastq_sum <- read_delim(fastqsum_fp) %>%
  group_by(SampleNumber) %>%
  #PF means reads that have passed filter
  summarise(total_raw_reads = sum(NumberOfReadsRaw),
            read_counts = sum(NumberOfReadsPF)) %>%
  ungroup()

# SampleSheet.csv loading

sample_sheet <- load_sample_sheet(SampleSheet_fp)

samp_sh_header <- data.frame(X1 = unlist(sample_sheet$Header)) %>%
  mutate(col_names = gsub(",.*", "", X1)) %>%
  mutate(col_names = gsub(" ", "_", col_names)) %>%
  mutate(X1 = gsub(".*,", "", X1)) %>%
  pivot_wider(names_from = "col_names", values_from = "X1")

samp_sh_check <- samp_sh_s <- data.frame(X1 = unlist(sample_sheet$Data), stringsAsFactors = FALSE) %>%
  #split each line into columns using row 1 as the column names
  separate(col = "X1", strsplit(as.character(slice(., 1)), ",")[[1]], sep = ",") %>%
  slice(-1) %>%
  rename(sample_id = "Sample_ID") %>%
  mutate(I7_ID = I7_Index_ID == UDI_Index_ID) %>%
  mutate(I5_ID = I5_Index_ID == UDI_Index_ID) %>%
  select(UDI_Index_ID, I7_ID, I5_ID)

#if any of the barcode ID's dont match, raise an error
if(!all(c(samp_sh_check$I7_ID, samp_sh_check$I7_ID))) {
  stop(simpleError("One of the barcode ID's don't match! Check samp_sh_check dataframe"))
}

samp_sh_s <- data.frame(X1 = unlist(sample_sheet$Data), stringsAsFactors = FALSE) %>%
  #split each line into columns using row 1 as the column names
  separate(col = "X1", strsplit(as.character(slice(., 1)), ",")[[1]], sep = ",") %>%
  slice(-1) %>%
  #this is for bcl2fastq
  #rename(SampleName = "Sample_Name", SampleNumber = "BASESPACE_ONLY_ORIGINAL_SAMPLE_NUMBER") %>%
  #mutate(Barcode_sequence = paste0(I7_Index_ID, "+", I5_Index_ID)) %>%
  #select(SampleName, I7_Index_ID, I5_Index_ID, Barcode_sequence, Sample_Type, UDI_Index_ID)
  rename(sample_id = "Sample_ID") %>%
  mutate(I7_Index_ID = index, I5_Index_ID = index2) %>%
  mutate(Barcode_sequence = paste0(I7_Index_ID, "+", I5_Index_ID)) %>%
  select(sample_id, I7_Index_ID, I5_Index_ID, Barcode_sequence, UDI_Index_ID) %>%
  mutate(sample_id = gsub("_", "-", sample_id))

#merge sample names with read counts
samp_reads <- read_delim(demuxsum_fp, col_names = FALSE) %>%
  filter(grepl("Sample", X1)) %>%
  t() %>%
  as.data.frame(stringsAsFactors = FALSE) %>%
  purrr::set_names(as.character(slice(., 1))) %>%
  slice(-1) %>%
  filter(!is.na(SampleNumber)) %>%
  merge(fastq_sum, by = "SampleNumber", all = TRUE) %>%
  rename(sample_id = "SampleName") %>%
  mutate(sample_id = gsub("_", "-", sample_id)) %>%
  mutate(sample_id = ifelse(sample_id == "None", "Undetermined", sample_id)) %>%
  merge(samp_sh_s, by = "sample_id", all = TRUE) %>%
  mutate(percent_reads_passed_filter = read_counts/total_raw_reads) %>%
  mutate(percent_of_lane = read_counts/sum(read_counts))


top_unkwn_indices <- read_delim(demuxsum_fp, col_names = FALSE) %>%
  filter(is.na(X6)) %>%
  filter(!is.na(X4)) %>%
  rename(index_sequence1 = "X1", index_sequence2 = "X3", number_of_reads = "X5") %>%
  filter(!grepl("###", index_sequence1)) %>%
  select(index_sequence1, index_sequence2, number_of_reads) %>%
  mutate(index_sequence = paste0(index_sequence1, "+", index_sequence2)) %>%
  select(-c(index_sequence1, index_sequence2)) %>%
  mutate(number_of_reads = as.numeric(number_of_reads)) %>%
  order_on_other_col(index_sequence, number_of_reads) %>%
  slice(1:10) %>%
  droplevels()

```

```{r load data}

kmer <- read_csv(kmer_fp) %>%
  mutate(`SARS-CoV-2` = factor(`SARS-CoV-2`, levels = c("ND", "Detected")))

n_clade <- read_csv(nextclade_fp) %>%
  rename(nc_QC_status = "QC Status") %>%
  mutate(n_VOC = gsub(".*\\(|\\).*", "", clade)) %>%
  mutate(n_VOC = gsub("^19A$", "Reference", n_VOC))

pango <- read_csv(pangolin_fp) %>%
  rename(pango_QC_status = "QC Status") %>%
  mutate(`Median Coverage` = gsub("\\(.*", "", `Median Coverage`)) %>%
  mutate(`Median Coverage` = gsub("$", "X", `Median Coverage`)) %>%
  mutate(`Scorpio Call` = gsub(" \\(.*", "", `Scorpio Call`)) %>%
  mutate(`Scorpio Call` = gsub("Probable ", "", `Scorpio Call`)) %>%
  mutate(`Scorpio Call` = ifelse(is.na(`Scorpio Call`) & Lineage == "B", "Reference", `Scorpio Call`)) %>%
  #version is messed up from converting an Excel to .csv format. The version seems to be reformmatted as a date
  mutate(Version = gsub(" 00:00:00$", "", Version)) %>%
  mutate(pango_software_v = gsub("^.*v|^.*v0", "", Version)) %>%
  mutate(pango_software_v = gsub("/|/20", ".", pango_software_v)) %>%
  mutate(pango_software_v = gsub("\\.0", "\\.", pango_software_v)) %>%
  #get the version between the two 'v'
  mutate(lineage_v = gsub("^.*-v", "", Version)) %>%
  mutate(lineage_v = gsub("v.*$", "", lineage_v)) %>%
  mutate(lineage_assign = gsub("-v.*", "", Version)) %>%
  mutate(coverage_num = as.numeric(gsub("%", "", `Coverage >= 30x`)))

bs_results <- merge(kmer, pango, by.x = "Sample", by.y = "Taxon", all = TRUE) %>%
  merge(n_clade, by.x = "Sample", by.y = "seqName", all = TRUE) %>%
  rename(sample_id = "Sample")

panogolin_database_version <- unique(bs_results$pango_software_v)[1]
lineage_assignment_software_version <- paste0(paste0(unique(bs_results$lineage_assign)[!is.na(unique(bs_results$lineage_assign))], collapse = "/"), " v", unique(bs_results$lineage_v)[1])

```

```{r sample_sheet_import and columns, echo=FALSE}
lookup <- c(sample_id = "SampleID",
            subject_id = "SubjectID",
            host_species = "HostSpecies",
            sample_type = "Sample_Type",
            final_library_conc_ng_ul = "final_library_concentration_ng_ul")
ctrl_regex <- "^EBneg.*|^Extract.*|^Vibriolambda.*|^Blank.*|^MockDNA.*|^DNAfreewater.*|^Geneblock.*|^Emptywell|Control"

s_meta <- read_delim(mapping_file_fp, delim = ",")

s <- s_meta %>%
  merge(samp_reads, by = c("sample_id", "UDI_Index_ID"), all = TRUE) %>%
  merge(bs_results, by = "sample_id", all = TRUE) %>%
  mutate(read_counts = ifelse(is.na(read_counts), 0, read_counts), total_raw_reads = ifelse(is.na(total_raw_reads), 0, total_raw_reads)) %>%
  rename(any_of(lookup)) %>%
  filter(!grepl("#", sample_id)) %>%
  mutate(isControl = grepl(ctrl_regex, sample_id, ignore.case = TRUE)|grepl(ctrl_regex, sample_type, ignore.case = TRUE)) %>%
    #make a new sample type based on if there were pangolin and nextclade results. DRAGEN App uses the <90 on the COVID targets as their threshold
  #Based on their manual, targets seem to be "amplicons" or regions of longer stretches of DNA that are unique to COVID (longer than their 32 k-mers that they use for k-mer detection)
  mutate(sample_type = case_when(((`SARS-CoV-2 Targets` < 90) & !grepl("control", sample_type)) ~ paste0(sample_type, " - No Variant Calls"),
                              grepl("^Undetermined$", sample_id) ~ "Unassigned reads",
                              TRUE ~ sample_type)) %>%
  #rearrange the sampletypes by ctrls first
  mutate(sample_type = factor(sample_type, levels =
                               unique(sample_type)[order(match(unique(sample_type), unique(sample_type)[grepl(ctrl_regex, gsub("-| ", "", unique(sample_type)), ignore.case = TRUE)]))])) %>%
  rename(lineage = "Lineage", scorpio = "Scorpio Call", coverage = "Median Coverage") %>%
  droplevels()

color_by <- NULL
shape_by <- NULL
quality_by <- "sample_type"
potential_headers <- c("study_group", "study_day", "subject_id",
                       "current_antibiotics", "host_species", "cage_number") #pick 2
header_idx <- which(is.element(potential_headers, colnames(s)))

if(length(header_idx)>0){
  color_by <- potential_headers[header_idx[1]]
}
if(length(header_idx)>1){
  shape_by <- potential_headers[header_idx[2]]
}

show.text <- nrow(s) > 40
```

```{r for basic report}

has_CT <- any(grepl("^CT$", colnames(s)))

has_RLU <- any(grepl("^RLU$", colnames(s)))

### ====================================
### Select specific groups to plot for QC
### ====================================
s_toPlot <- s %>%
  filter(!grepl("None|Undetermined", sample_id)) %>%
  filter(!grepl(" - No Variant Calls$", sample_type)) %>%
  mutate(sample_id = as.character(sample_id)) %>%
  droplevels()

```

```{r colors}

ann_colors <- list()

#variables to test and colors
sg_toTest <- c("sample_type")

for(g in sg_toTest) {
  lvls <- c(levels(s[, g]), NA)
  g_colors <- setNames(pal_d3("category20")(20)[1:length(lvls)], lvls)
  ann_colors[[g]] <- g_colors
}

#scales::show_col(ann_colors[[sg_toTest]])

```

```{r variant colors}

i <- 1
ann_colors[["variants"]] <- c()
ann_colors[["who_label"]] <- c()

for(variant in sort(unique(s$scorpio)[!is.na(unique(s$scorpio))])) {
  
  #only coloring first two variants
  variant_list <- s %>%
    filter(scorpio == variant) %>%
    select(Note) %>%
    mutate(Note = gsub(".*: ", "", Note)) %>%
    separate(Note, into = c("variant1", "variant2"), sep = " ", extra = "merge") %>%
    filter(!grepl("Assigned", variant1)) %>%
    filter(!grepl("scorpio found insufficient support.*", variant2)) %>%
    mutate(variant2 = gsub("scorpio lineage | conflicts with inference lineage .*", "", variant2)) %>%
    pivot_longer(cols = c("variant1", "variant2"), names_to = "variant_num", values_to = "variants") %>%
    mutate(variants = gsub("\\(.*", "", variants)) %>%
    select(variants) %>%
    filter(!is.na(variants)) %>%
    unique() %>%
    pull() %>%
    str_sort(numeric = TRUE)
  
  variant_color <- brewer.pal(8, "Dark2")[i]
  
  variant_gradient <- colorRampPalette(c(variant_color, adjustcolor(variant_color, alpha.f = 0.1)), alpha = TRUE)(length(variant_list))
  names(variant_gradient) <- variant_list
  
  who_color <- variant_color
  names(who_color) <- variant
  
  ann_colors[["variants"]] <- c(ann_colors[["variants"]], variant_gradient)
  ann_colors[["who_label"]] <- c(ann_colors[["who_label"]], who_color)
  
  i <- i + 1
  
}

ann_colors[["variants"]] <- c("#80808080", ann_colors[["variants"]])
names(ann_colors[["variants"]]) <- c(NA, names(ann_colors[["variants"]])[-1])

#scales::show_col(ann_colors[["variants"]])

who_legend <- data.frame(x = 1, y = 1, fill_col = names(ann_colors[["who_label"]])) %>%
  ggplot(aes(x = x, y = y, fill = fill_col)) +
    geom_bar(stat="identity", position = position_fill(reverse = TRUE), alpha = 0) +
    scale_fill_manual(values = ann_colors$who_label) +
    guides(fill = guide_legend(override.aes = list(alpha=1), reverse=T, order = 1)) + 
    theme_bw() +
    theme(
      strip.text = element_text(size = 12),
      strip.background = element_blank(),
      panel.grid = element_blank(),
      panel.border = element_blank(),
      axis.title = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank(),
      legend.position = c(0.5, 0.5), # move the legend to the center
      plot.margin=unit(c(0, 0, 0, 0), "cm")
    ) +
    labs(fill = "WHO label", y = "", x = "")

```

```{r empty plate to plot}
empty_plate <- data.frame(plate_row = unlist(lapply(LETTERS[1:8], function(x) rep(x, 12))), plate_col = rep(1:12, 8), plate = 1) %>%
  mutate(plate_coord = paste0(plate, "_", plate_row, plate_col))

```

```{r}
```
