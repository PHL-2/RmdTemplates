---
title: |
    | 
    | 
    | 
    | 
    | ![](../aux_files/pdf_generation/forKnitting/logo_blk.png){width=4.5in}  
    | 
    | Sequencing Lab
    | 
    | QC report for sequencing run
    | 
    | `r basename(here())`

author: "Philadelphia Public Health Laboratory"
date: \today
geometry: margin=3cm
output:
    pdf_document:
        template: ../aux_files/pdf_generation/forKnitting/toc_after.tex
        keep_tex: false
        toc: true
        toc_depth: 3
        includes:
            in_header: ../aux_files/pdf_generation/forKnitting/TeX_packages_commands.sty

---

\newpage

\tableofcontents

```{r settings for processing the sequencing run, include=FALSE, eval=FALSE}

#####################################################################
# 1_remove_low_RLU.R (Cleaning up metadata sheet and making platemap)
#####################################################################

create_sample_replicates <- 4 #enter a positive integer for the number of biological replicates created during concentration and extraction

# set this to TRUE to copy the platemap to the shared drive
copy_platemap <- TRUE

###################################################################################
# 2_generate_barcodes_IDT.R and 3_archive_upload_run.R (BaseSpace and AWS settings)
###################################################################################

run_uploaded_2_basespace <- FALSE # set this to true if the run was uploaded to BaseSpace and the data was not manually transferred to a local folder

sequencer_select <- 2 # set variable as 1 for MiSeq or 2 for NextSeq

have_AWS_EC2_SSH_access <- TRUE

remove_sample_from_bcl_samplesheet <- c("") #add in sample names to remove from demultiplexing

sample_w_empty_reads <- c("") #add in sample ids that have empty fastq files

####################################
# 4_run_nextflow.R (Cecret settings)
####################################

#tag of nextclade dataset to use for lineage assignment
#leave empty to use the latest nextclade dataset
nextclade_dataset_version <- ""

update_freyja_and_cecret_pipeline <- TRUE

cecret_version <- "3.15.24324"

```

```{r select samples and ddpcr metadata, message = TRUE, include=FALSE, eval = FALSE}

#this script uses a wastewater sample selection sheet to create a sequencing plate map for the wet lab
#a metadata sheet with the ddPCR values for the selected samples will also be generated
#the selection sheet should be placed in the extra_metadata folder
#any samples from previous runs included should be placed in the prev_run folder
source("code/1_select_sample_n_metadata.R")

```

```{r generate sequencing metadata and sample barcodes, message = TRUE, include=FALSE, eval = FALSE}

#this script generates the SampleSheet.csv file required for demultiplexing the sequencing run
#the required file to include is the sequencing_metadata_sheet.xlsx filled out by the sequencing wet lab scientists, pertaining to the barcodes assigned to the samples
source("code/2_generate_barcodes_IDT.R")

```

```{r archive and upload sequencing run data, message = TRUE, include=FALSE, eval = FALSE}

#this script compresses the sequencing run folder and uploads it to S3, along with auxiliary files

source("code/3_archive_upload_run.R")

```

```{r run nextflow, message = TRUE, include=FALSE, eval = FALSE}

#this script submits the nextflow jobs for demultiplexing and running the cecret pipeline to the ec2 instance

source("code/4_run_nextflow.R")

```

```{r setup for the pdf, echo=FALSE}

library(knitr)
opts_chunk$set(
  tidy=FALSE,
  cache=FALSE,
  cache.lazy = FALSE,
  echo=FALSE,
  warning=FALSE,
  message=FALSE, #Set message to NA in chunks where message should be sent to stderr
  dpi=100,
  fig.width=6,
  fig.height=6,
  dev.args = list(pdf = list(useDingbats = FALSE))
)

#this lets you loop through variables and produce multiple pander tables and ggplots in a single code block!
#this also means that you have to put results='asis' in any block that has pander output
pander::panderOptions("knitr.auto.asis", FALSE)

```

```{r load data, child = 'code/preamble.Rmd', eval = load_preamble}

```

```{r make figures, child = 'code/data_analysis.Rmd'}

```

```{r generate time stamped report, message=TRUE, include=FALSE, eval=FALSE}
#generate the pdf report

### =============
### Manual inputs
### =============

# need to import the data into a single tsv for the first time?
import_data <- TRUE
report_only_cdc_lineages <- TRUE

### =================
### End manual inputs
### =================

rstudioapi::documentSaveAll()
library(here)
dir.create(here("output"))
project_name <- basename(here())

qc_report_fp <- paste0(project_name, "_QC_Report.Rmd")
qc_output_fp <- here("output", paste0(project_name, '.QC.report_gen.on.', Sys.Date(), '.pdf'))

# load preamble the first time?
load_preamble <- TRUE

# print table as kable for pdf?
use_kable <- TRUE
rmarkdown::render(qc_report_fp, output_file = qc_output_fp)

load_preamble <- FALSE
use_kable <- FALSE
rmarkdown::render(qc_report_fp, output_file = "README.md",
                 output_format = rmarkdown::md_document(variant = "gfm", toc = TRUE))

```

```{r run R script, include=FALSE, eval=FALSE}

rstudioapi::documentSaveAll()
library(here)

#this file needs to sit in a [aux_files/config] directory path above this project directory
tryCatch(
  {
    source(file.path(dirname(here()), "aux_files", "r_scripts", "config", "config_variables.R"))
  },
  error = function(e) {
  stop (simpleError("The config_variables.R file needs to sit in a [aux_files/r_scripts/config] directory path above this project directory"))
  }
)

project_name <- basename(here())

copy_to <- file.path(shared_drive_fp, "Sequencing_results", "COVIDSeq", "wastewater")
dir.create(file.path(copy_to, project_name), recursive = TRUE)

pdf_fp <- here("output", list.files(here("output"), pattern = ".pdf"))
for(i in pdf_fp){
  file.copy(i, file.path(copy_to, project_name), overwrite = TRUE)
}

file.copy(here("upload", "epi"), file.path(copy_to, project_name), recursive = TRUE, overwrite = TRUE)

```

```{r GISAID BioSample SRA submission, message=TRUE, include=FALSE, eval=FALSE}

#seqsender submit. Check that the GISAID sample_id always have "Merged" in the name; check that the bs-GISAID virus name field also has "Merged" in the name

#check to make sure the seqsender file has these fields from the metadata sheet
#to check
#covv_orig_lab_addr,
#covv_virus_name, (make sure the final GISAID submission file has this column, should be from gs-sample_name)
# In BioSample, see if sample_description comes up as description and whether it is in the right xml field
#In BioSample, see if isolate shows up in the xml file and whether it passes the test

### =============
### Manual inputs
### =============

#do a test upload first. change this to FALSE when SRA upload and gisaid upload testing is successful and you want to submit the files for real
test_upload <- TRUE

#the PHL2 sample_id of samples to remove from the merged FASTA sample
#should be in the format of PHL2-[sequencer]-[plate position]-[sequencing date]
failed_sample_fasta <- c("")

### =================
### End manual inputs
### =================

rstudioapi::documentSaveAll()
library(here)
library(readr)
library(tidyverse)

#load constant variables
tryCatch(
  {
    source(file.path(dirname(here()), "aux_files", "r_scripts", "config", "config_variables.R"))
  },
  error = function(e) {
  stop (simpleError("The config_variables.R file needs to sit in a [aux_files/r_scripts/config] directory path above this project directory"))
  }
)

#load functions
tryCatch(
  {
    source(file.path(dirname(here()), "aux_files", "r_scripts", "functions", "R_all_functions_v3.R"))
  },
  error = function(e) {
  stop (simpleError("The R_all_functions_v3.R file needs to sit in a [aux_files/r_scripts/functions] directory path above this project directory"))
  }
)

ssh_seqsender_cmd <- function(pos_argument,
                              ssh_destination = ec2_hostname, 
                              python_script = seqsender_py,
                              organism = organism_flag,
                              submission_dir = submission_path,
                              submission_name = project_name,
                              config = config2use,
                              metadata = ec2_seqsender_meta_fp,
                              fasta = consensus_fasta_fp,
                              is_test = test_flag) {
  
  additional_flags <- paste(organism,
                            "--config_file", config,
                            "--metadata_file", metadata,
                            "--fasta_file", fasta)
  
  success_msg <- unlist(lapply(c("BIOSAMPLE", "SRA", "GENBANK", "GISAID"),
                                 function(x) c(paste("Creating submission files for", x),
                                               paste("Files are stored at:", paste(submission_dir, submission_name, "submission_files", x, sep = "/")))))
  
  if (pos_argument == "prep --gisaid") {
    success_msg <- success_msg[grepl("GISAID", success_msg)]

  } else if (pos_argument == "prep -bsn") {
    success_msg <- success_msg[grepl("BIOSAMPLE|SRA|GENBANK", success_msg)]
    
  } else if (pos_argument == "submit --biosample --sra") {
    additional_flags <- paste(additional_flags, is_test)
    
    success_msg <- c(success_msg[grepl("BIOSAMPLE|SRA", success_msg)],
                     "Connecting to NCBI FTP Server",
                     paste0("Submission name: ", submission_name, c("_BIOSAMPLE", "_SRA")),
                     paste0("Submitting '", submission_name, "'"))
    
  } else if (pos_argument == "submit --genbank") {
    additional_flags <- paste(additional_flags, is_test)
    
    success_msg <- c(success_msg[grepl("GENBANK", success_msg)],
                     "Connecting to NCBI FTP Server",
                     paste0("Submission name: ", submission_name, "_GENBANK"),
                     paste0("Submitting '", submission_name, "'"))
  } else if (pos_argument == "submission_status") {
    additional_flags <- ""
    
    success_msg <- c("Checking Submissions:",
                     paste("Submission:", submission_name),
                     "Downloading report.xml",
                     "Updating submissions complete.")
  }
                                                     
  check_err_msg <- system2("ssh", c("-tt", ssh_destination,
                                    shQuote(paste("conda activate seqsender;",
                                                  "python", python_script, pos_argument,
                                                  "--submission_dir", submission_dir,
                                                  "--submission_name", submission_name,
                                                  additional_flags), type = "sh")),
                           stdout = TRUE, stderr = TRUE) %>%
    gsub("\\\r$", "", .)
  
  warning(simpleWarning(paste(check_err_msg, collapse = "\n")))
  
  if(!all(success_msg %in% check_err_msg)) {
    stop(simpleError(paste("\nSeqsender process", pos_argument, "failed!")))
  }
}

ssh_command_check <- function(stdoutput) {
  if(any(grepl("Could not resolve hostname|Operation timed out|BrokenPipeError|No such file or directory", stdoutput))) {
    stop(simpleError("SSH command to EC2 command failed"))
  }
}

#################################
# Load project specific variables
#################################

project_name <- basename(here())
aux_seqsender_fp <- file.path(dirname(here()), "aux_files", "data_submission", "seqsender")
seqsender_meta_fp <- here("upload", "seqsender", paste(project_name, "PHL2_seqsender_upload_orig.csv", sep = "_"))
appended_seqsender_meta_fp <- here("upload", "seqsender", paste(project_name, "PHL2_seqsender_upload.csv", sep = "_"))

#path of local seqsender config file
seqsender_config_fp <- list.files(aux_seqsender_fp, pattern = "seqsender_ww_login_config.yaml", full.names = TRUE)

#sequencing date of the run folder should match the RStudio project date
sequencing_date <- gsub("_.*", "", basename(here())) #YYYY-MM-DD

#if this sample sheet file is missing, download it manually from AWS S3 bucket
sample_sheet_fn <- list.files(here("metadata", "munge"), pattern = "SampleSheet_v2.csv")

#get sequencer of the run
sequencer_type <- gsub("^[0-9-]*_(MiSeq|NextSeq1k2k)_.*", "\\1", sample_sheet_fn)

#get sample type
sample_type_acronym <- gsub(paste0("^[0-9-]*_", sequencer_type, "_|_.*"), "", sample_sheet_fn)

authors <- gsub(", .*|,.*", "", bioinformatician_name)

#checks
if(sequencing_date == "") {
  stop (simpleError(paste0("Please fill in the correct sequencing date or short project description")))
} else if (is.na(as.Date(sequencing_date, "%Y-%m-%d")) | nchar(sequencing_date) == 8) {
  stop (simpleError("Please enter the date into [sequencing_date] as YYYY-MM-DD"))
}

if(length(sample_sheet_fn) > 1) {
  stop(simpleError("There are more than 2 sample sheets detected!! Please delete the incorrect one"))
} else if(length(sample_sheet_fn) == 0) {
  stop(simpleError("Sample sheet with suffix '_SampleSheet_v2.csv' is missing. Download this file manually from AWS S3 bucket"))
}

if(bioinformatician_name == "") {
  stop (simpleError(paste0("Please fill in bioinformatician_name in config_variables.R")))
}

####################################
# Define AWS variables and filepaths
####################################

#path of where the seqsender repo was cloned, do not use tilde (~) in path
seqsender_fp <- "/home/ec2-user/git/seqsender"
seqsender_upload_tmp_fp <- "/home/ec2-user/tmp_data_ul"
workflow_output_fp <- paste(s3_nextflow_output_bucket, "cecret", sample_type_acronym, project_name, sequencer_type, sep = "/")
submission_path <- paste(seqsender_upload_tmp_fp, sample_type_acronym, sep = "/")
ec2_upload_tmp_fp <- paste(submission_path, project_name, sep = "/")
consensus_fasta_fp <- paste(ec2_upload_tmp_fp, "processed_cecret", "merged_consensus",
                            paste0(project_name, "_PHL2_combined.fasta"), sep = "/")
ec2_seqsender_meta_fp <- paste0(ec2_upload_tmp_fp, "/seqsender/", paste(project_name, "PHL2_seqsender_upload.csv", sep = "_"))

seqsender_py <- paste(seqsender_fp, "seqsender.py", sep = "/")
covCLI_cmd <- paste(seqsender_fp, "gisaid_cli", "covCLI", sep = "/")

if(test_upload) {
  test_flag <- "--test"
  gs_client_id <- "TEST-EA76875B00C3"
  local_gs_log <- here("gisaid", paste0(project_name, "_gisaid_test.log"))
  BioProject <- bio_prj_id_test
} else {
  test_flag <- ""
  gs_client_id <- gisaid_client_id
  local_gs_log <- here("gisaid", paste0(project_name, "_gisaid.log"))
  BioProject <- bio_prj_id_ww
}

organism_flag <- "--organism COV"
config2use <- paste0(ec2_upload_tmp_fp, "/seqsender/", basename(seqsender_config_fp))
ec2_gs_log <- paste0(ec2_upload_tmp_fp, "/submission_files/GISAID/", basename(local_gs_log))

#######################
# Read in seqsender csv
#######################
seqsender <- read_csv(seqsender_meta_fp) %>%
  filter(!sequence_name %in% failed_sample_fasta,
         !is.na(`bs-sample_name`)) %>%
  mutate(authors = authors,
         bioproject = BioProject)

seqsender %>%
  write_csv(appended_seqsender_meta_fp, na = "")

passed_fasta_files <- seqsender %>%
  filter(`gs-sample_name` != "") %>%
  select(sequence_name) %>%
  pull()

if(nrow(seqsender) < 1) {
  stop(simpleError("No samples passed QC for data submission. Don't have to submit this run"))
}

######################
# Run seqsender on EC2
######################

cecret_file_download_command <- c("aws s3 cp", workflow_output_fp)
cecret_file_download_param <- c("--recursive",
                                "--exclude '*'",
                                paste0("--include '*/filter/", seqsender$sequence_name, "*_filtered_R[12].fastq.gz'"),
                                paste0("--include '*/ivar_consensus/", passed_fasta_files, "*.consensus.fa'"))

aws_s3_cecret_download <- system2("ssh", c("-tt", ec2_hostname,
                                           shQuote(paste0("rm -rf ", ec2_upload_tmp_fp, "; ",
                                                          paste(c(cecret_file_download_command,
                                                                  ec2_upload_tmp_fp,
                                                                  cecret_file_download_param), collapse = " "), "; ",
                                                          "mkdir -p ", ec2_upload_tmp_fp, "/raw_reads; ",
                                                          "find ", ec2_upload_tmp_fp, " -name '*_filtered_R[12].fastq.gz' -exec mv -t ",
                                                          ec2_upload_tmp_fp, "/raw_reads/ {} +"),
                                                   type = "sh")),
                                  stdout = TRUE, stderr = TRUE)

ssh_command_check(aws_s3_cecret_download)

create_concat_consensus <- system2("ssh", c("-tt", ec2_hostname,
                                            shQuote(paste0("mkdir -p ", dirname(consensus_fasta_fp), "; ",
                                                           "sed -E 's/^N+|N+$|Consensus_|_S[0-9]*.consensus_threshold.*//g' ",
                                                           ec2_upload_tmp_fp, "/processed_cecret/ivar_consensus/* > ",
                                                           consensus_fasta_fp, ";"), type = "sh")),
                                   stdout = TRUE, stderr = TRUE)

dir.create(here("upload", "fasta"))

download_consensus <- system2("scp", c(paste0(ec2_hostname, ":", consensus_fasta_fp),
                                       here("upload", "fasta/")),
                              stdout = TRUE, stderr = TRUE)

ssh_command_check(c(create_concat_consensus, download_consensus))

upload_seqsender_files <- system2("scp", c(appended_seqsender_meta_fp, seqsender_config_fp,
                                           paste0(ec2_hostname, ":", ec2_upload_tmp_fp, "/seqsender")))
                                  
ssh_command_check(upload_seqsender_files)

ssh_seqsender_cmd("prep --gisaid")

dir.create(here("gisaid"))

# check the seqsender file for GISAID accession numbers
# if the seqsender file already has legit GISAID accession numbers, don't resubmit because GISAID already has these samples
# have to manually submit GISAID files because the password field in seqsender does not accept all special characters
if(all(grepl("^EPI_ISL_0$", seqsender$`bs-gisaid_accession`)) | all(is.na(seqsender$`bs-gisaid_accession`))) {
  
  # clear these GISAID log files if exist
  file.remove(local_gs_log)
  
  # submit files to gisaid
  # covCLI is a program that can be downloaded from gisaid.org; add it to $PATH
  run_in_terminal(paste("ssh -tt", ec2_hostname,
                        shQuote(paste(covCLI_cmd, "upload",
                                      "--clientid", gs_client_id,
                                      "--username", gisaid_username,
                                      "--metadata", paste(ec2_upload_tmp_fp, "submission_files", "GISAID", "metadata.csv", sep = "/"),
                                      "--fasta", paste(ec2_upload_tmp_fp, "submission_files", "GISAID", "sequence.fsa", sep = "/"),
                                      "--frameshift", "catch_novel",
                                      "--log", ec2_gs_log), type = "sh")))
  
  rstudioapi::executeCommand('activateConsole')
  
  download_gisaid_load <- system2("scp", c(paste0(ec2_hostname, ":", ec2_gs_log), local_gs_log))
  
  ssh_command_check(download_gisaid_load)
  
}

# read in the GISAID log file
# if upload was successful, grab the GISAID accessions for the BioSample submissions
read_gisaid_accessions <- read_csv(local_gs_log, col_names = c("code", "msg", "timestamp"))

gisaid_errors <- read_gisaid_accessions %>%
  filter(grepl("error", code, ignore.case = TRUE))

if(nrow(gisaid_errors) > 0) {
  stop(simpleError(paste0("Something went wrong! GISAID upload failed. Did you use the wrong credentials?\n",
                          "This error may also occur if these samples have been already uploaded\n",
                          "Depending on following error message, you may be able to just rerun this chunk to resubmit:\n",
                          gisaid_errors)))
}

gisaid_success <- read_gisaid_accessions %>%
  filter(grepl("epi_isl_id", code))

if(nrow(gisaid_success) != nrow(seqsender)) {
  stop(simpleError("Some GISAID samples failed to upload."))
}
  
gisaid_accessions <- gisaid_success %>%
  mutate(msg = gsub("^msg: ", "", msg)) %>%
  separate(msg, into = c("bs-gisaid_virus_name", "bs-gisaid_accession"), sep = "; ", extra = "merge") %>%
  #mutate(`src-note` = paste0("GISAID virus name: ", `bs-gisaid_virus_name`, "; GISAID accession: ", `bs-gisaid_accession`)) %>%
  select(`bs-gisaid_virus_name`, `bs-gisaid_accession`)
  
if(!test_upload) {
  #if there is a connection error for the real submission, start appending to the file, instead of rewriting it each time. Find a way to keep the column name the same
  gisaid_accessions %>%
    write_csv(here("gisaid", paste0(project_name, "_gisaid_accessions.csv")))
}

#rewrite the seqsender file with the gisaid accession numbers and remove the old prepared files
seqsender %>%
  select(-c(`bs-gisaid_accession`)) %>%
  left_join(gisaid_accessions, by = "bs-gisaid_virus_name") %>%
  #mutate(`src-note` = paste0(`src-note`, "; Lineage: ", `bs-lineage/clade name`)) %>%
  write_csv(appended_seqsender_meta_fp)

reupload_seqsender_file <- system2("scp", c(appended_seqsender_meta_fp, paste0(ec2_hostname, ":", ec2_seqsender_meta_fp)))

ssh_command_check(reupload_seqsender_file)

### can uncomment the below command to create the NCBI files to check manually before submission
#ssh_seqsender_cmd("prep -bsn")

### submit files to biosample and sra
ssh_seqsender_cmd("submit --biosample --sra")

#download submission file
download_submission_log <- system2("scp", c(paste0(ec2_hostname, ":", submission_path, "/submission_log.csv"), dirname(here())))

ssh_command_check(download_submission_log)

```

