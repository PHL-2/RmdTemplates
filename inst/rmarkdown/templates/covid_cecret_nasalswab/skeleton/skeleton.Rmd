---
title: |
  ![](../aux_files/pdf_generation/forKnitting/logo_blk.png){width=4.5in}  
  `r paste0('QC report for sequencing run')`
  `r basename(here())`
author: "Philadelphia Public Health Labs"
date: \today
geometry: margin=3cm
output:
    pdf_document:
        template: ../aux_files/pdf_generation/forKnitting/toc_after.tex
        keep_tex: false
        toc: true
        toc_depth: 3
        includes:
            in_header: ../aux_files/pdf_generation/forKnitting/TeX_packages_commands.sty

---

\newpage

\tableofcontents

```{r filter out samples, message = TRUE, include=FALSE, eval = FALSE}

#this script filters the Excel file provided by the epidemiologist by excluding low RLU samples and samples received by the Health Centers
#the Excel file should be placed in the extra_metadata folder along with the environmental swabs file
#any samples from previous runs included should be placed in the prev_run folder, using the filtered Excel file
source("code/1_remove_low_RLU.R")

```

```{r generate SampleSheet and metadata, message = TRUE, include=FALSE, eval = FALSE}

#this script generates the SampleSheet.csv file required for demultiplexing the sequencing run
#the required file to include is the sequencing_metadata_sheet.xlsx filled out by the sequencing wet lab scientists, pertaining to the barcodes assigned to the samples
source("code/2_generate_barcodes_IDT.R")

```

```{r upload sequencing run data, message = TRUE, include=FALSE, eval = FALSE}

#this script compresses the sequencing run folder and uploads it to S3, along with auxiliary files

source("code/3_archive_upload_run.R")

```

```{r run nextflow, message = TRUE, include=FALSE, eval = FALSE}

#this script submits the nextflow jobs for demultiplexing and running the cecret pipeline to the ec2 instance

source("code/4_run_nextflow.R")

```

```{r setup for the pdf, echo=FALSE}

library(knitr)
opts_chunk$set(
  tidy=FALSE,
  cache=FALSE,
  cache.lazy = FALSE,
  echo=FALSE,
  warning=FALSE,
  message=FALSE, #Set message to NA in chunks where message should be sent to stderr
  dpi=100,
  fig.width=6,
  fig.height=6,
  dev.args = list(pdf = list(useDingbats = FALSE))
)

#this lets you loop through variables and produce multiple pander tables and ggplots in a single code block!
#this also means that you have to put results='asis' in any block that has pander output
pander::panderOptions("knitr.auto.asis", FALSE)

```

```{r load data, child = 'code/preamble.Rmd', eval = load_preamble}

```

```{r make figures, child = 'code/data_analysis.Rmd'}

```

```{r generate time stamped report, message=TRUE, include=FALSE, eval=FALSE}
#generate the pdf report

### =============
### Manual inputs
### =============

# need to import the data into a single tsv for the first time?
import_data <- TRUE

# have the original sample accession numbers file to report the results to DDC?
have_phi <- TRUE

### =================
### End manual inputs
### =================

rstudioapi::documentSaveAll()
library(here)
dir.create(here("output"))
project_name <- basename(here())

qc_report_fp <- paste0(project_name, "_QC_Report.Rmd")
qc_output_fp <- here("output", paste0(project_name, '.QC.report_gen.on.', Sys.Date(), '.pdf'))

# load preamble the first time?
load_preamble <- TRUE

# print table as kable for pdf?
use_kable <- TRUE
rmarkdown::render(qc_report_fp, output_file = qc_output_fp)

load_preamble <- FALSE
use_kable <- FALSE
rmarkdown::render(qc_report_fp, output_file = "README.md",
                 output_format = rmarkdown::md_document(variant = "gfm", toc = TRUE))

```

```{r run R script, include=FALSE, eval=FALSE}

rstudioapi::documentSaveAll()
library(here)

#this file needs to sit in a [aux_files/r_scripts/config] directory path above this project directory
tryCatch(
  {
    source(file.path(dirname(here()), "aux_files", "r_scripts", "config", "config_variables.R"))
  },
  error = function(e) {
  stop (simpleError("The config_variables.R file needs to sit in a [aux_files/r_scripts/config] directory path above this project directory"))
  }
)

project_name <- basename(here())
PHI_file_fp <- list.files(here("metadata"), pattern = "_PHI.csv", full.names = TRUE)

copy_to <- file.path(shared_drive_fp, "Sequencing_results", "COVIDSeq", "nasal_swabs")
dir.create(file.path(copy_to, project_name, "metadata"), recursive = TRUE)

file.copy(PHI_file_fp, file.path(copy_to, project_name, "metadata"), overwrite = TRUE)

pdf_fp <- here("output", list.files(here("output"), pattern = ".pdf"))
for(i in pdf_fp){
  file.copy(i, file.path(copy_to, project_name), overwrite = TRUE)
}

file.copy(here("upload", "epi"), file.path(copy_to, project_name), recursive = TRUE, overwrite = TRUE)

```

```{r upload sequencing results, message=TRUE, include=FALSE, eval=FALSE}

### =============
### Manual inputs
### =============

#do a test upload first. change this to FALSE when SRA upload and gisaid upload testing is successful and you want to submit the files for real
test_upload <- TRUE

#change this flag to FALSE to not use proxy
use_proxy <- FALSE 

#change this to TRUE to overwrite the submitted files on the sFTP and to resubmit
overwrite <- FALSE

### =================
### End manual inputs
### =================

rstudioapi::documentSaveAll()
library(here)
library(readr)
library(tidyverse)

#load constant variables
tryCatch(
  {
    source(file.path(dirname(here()), "aux_files", "r_scripts", "config", "config_variables.R"))
  },
  error = function(e) {
  stop (simpleError("The config_variables.R file needs to sit in a [aux_files/r_scripts/config] directory path above this project directory"))
  }
)

#load functions
tryCatch(
  {
    source(file.path(dirname(here()), "aux_files", "r_scripts", "functions", "R_all_functions_v3.R"))
  },
  error = function(e) {
  stop (simpleError("The R_all_functions_v3.R file needs to sit in a [aux_files/r_scripts/functions] directory path above this project directory"))
  }
)

ssh_seqsender_cmd <- function(seqsender_flag,
                              ssh_destination = ec2_hostname, prj_dir = ec2_upload_tmp_fp,
                              python_script = seqsender_py, use_proxy = proxy_flag,
                              unique_name = project_name, config = config2use,
                              metadata = ec2_seqsender_meta_fp, fasta = consensus_fasta_fp,
                              is_test = test_flag, is_overwrite = overwrite_flag) {
  
  success_msg <- c(paste0("Processing ", unique_name),
                   "Processing Files", 
                   "Creating GISAID files",
                   "Creating Genbank files",
                   "Creating BioSample/SRA files",
                   paste0(unique_name, " complete"))
  
  additional_flags <- paste("--metadata", metadata, "--fasta", fasta)

  if (seqsender_flag == "submit") {
    additional_flags <- paste(additional_flags, is_test, is_overwrite)
    success_msg <- c(success_msg,
                     "Submitting to SRA/BioSample")
  } else if (seqsender_flag == "genbank") {
    additional_flags <- paste(is_test, is_overwrite)
    success_msg <- c("Zipping submission files",
                     "Submitting to Genbank")
  }
                                                     
  check_err_msg <- system2("ssh", c("-tt", ssh_destination,
                                    shQuote(paste("cd", paste0(prj_dir, ";"),
                                                  "conda activate seqsender;",
                                                  "python", python_script, use_proxy, seqsender_flag,
                                                  "--unique_name", unique_name,
                                                  "--config", config,
                                                  additional_flags), type = "sh")),
                           stdout = TRUE, stderr = TRUE) %>%
    gsub("\\.\\\r", "", .)
  
  warning(simpleWarning(check_err_msg))
  
  if(!all(success_msg %in% check_err_msg)) {
    stop(simpleError(paste("Seqsender process", seqsender_flag, "failed!")))
  }
}

ssh_command_check <- function(stdoutput) {
  if(any(grepl("Could not resolve hostname|Operation timed out|BrokenPipeError|No such file or directory", stdoutput))) {
    stop(simpleError("SSH command to EC2 command failed"))
  }
}

#################################
# Load project specific variables
#################################

project_name <- basename(here())
seqsender_py <- file.path(seqsender_fp, "seqsender.py")
aux_seqsender_fp <- file.path(dirname(here()), "aux_files", "data_submission", "seqsender")
seqsender_meta_fp <- here("upload", "seqsender", paste(project_name, "PHL2_seqsender_upload.tsv", sep = "_"))

#path of local seqsender config file
seqsender_config_test_fp <- list.files(aux_seqsender_fp, pattern = "seqsender_ns_config_test.yaml", full.names = TRUE)
seqsender_config_fp <- list.files(aux_seqsender_fp, pattern = "seqsender_ns_config.yaml", full.names = TRUE)

#sequencing date of the run folder should match the RStudio project date
sequencing_date <- gsub("_.*", "", basename(here())) #YYYY-MM-DD

#if this sample sheet file is missing, download it manually from AWS S3 bucket
sample_sheet_fn <- list.files(here("metadata", "munge"), pattern = "SampleSheet_v2.csv")

#get sequencer of the run
sequencer_type <- gsub("^[0-9-]*_(MiSeq|NextSeq1k2k)_.*", "\\1", sample_sheet_fn)

#get sample type
sample_type_acronym <- gsub(paste0("^[0-9-]*_", sequencer_type, "_|_.*"), "", sample_sheet_fn)

#checks
if(sequencing_date == "") {
  stop (simpleError(paste0("Please fill in the correct sequencing date or short project description")))
} else if (is.na(as.Date(sequencing_date, "%Y-%m-%d")) | nchar(sequencing_date) == 8) {
  stop (simpleError("Please enter the date into [sequencing_date] as YYYY-MM-DD"))
}

if(length(sample_sheet_fn) > 1) {
  stop(simpleError("There are more than 2 sample sheets detected!! Please delete the incorrect one"))
} else if(length(sample_sheet_fn) == 0) {
  stop(simpleError("Sample sheet with suffix '_SampleSheet_v2.csv' is missing. Download this file manually from AWS S3 bucket"))
}

####################################
# Define AWS variables and filepaths
####################################

workflow_output_fp <- paste(s3_nextflow_output_bucket, "cecret", sample_type_acronym, project_name, sequencer_type, sep = "/")
ec2_upload_tmp_fp <- paste(seqsender_upload_tmp_fp, sample_type_acronym, project_name, sep = "/")
consensus_fasta_fp <- paste(ec2_upload_tmp_fp, "processed_cecret", "merged_consensus",
                            paste0(project_name, "_PHL2_combined.fasta"), sep = "/")
ec2_seqsender_meta_fp <- paste0(ec2_upload_tmp_fp, "/seqsender/", paste(project_name, "PHL2_seqsender_upload.tsv", sep = "_"))

if(test_upload) {
  test_flag <- "--test"
  config2upload <- seqsender_config_test_fp
  gs_client_id <- "TEST-EA76875B00C3"
  local_gs_log <- here("gisaid", paste0(project_name, "_gisaid_test.log"))
} else{
  test_flag <- ""
  config2upload <- seqsender_config_fp
  gs_client_id <- gisaid_client_id
  local_gs_log <- here("gisaid", paste0(project_name, "_gisaid.log"))
}

if(use_proxy) {
  proxy_flag <- "--proxy"
} else{
  proxy_flag <- ""
}

if(overwrite) {
  overwrite_flag <- "--overwrite"
} else{
  overwrite_flag <- ""
}

config2use <- paste0(ec2_upload_tmp_fp, "/seqsender/", basename(config2upload))
ec2_gs_log <- paste0(ec2_upload_tmp_fp, "/gisaid/", basename(local_gs_log))

#######################
# Read in seqsender tsv
#######################
seqsender <- read_tsv(seqsender_meta_fp)

passed_fasta_files <- seqsender %>%
  filter(genbank_name != "") %>%
  select(sample_id) %>%
  pull()

if(nrow(seqsender) < 1) {
  stop(simpleError("No samples passed QC for data submission. Don't have to submit this run"))
}

######################
# Run seqsender on EC2
######################

cecret_file_download_command <- c("aws s3 cp", workflow_output_fp)
cecret_file_download_param <- c("--recursive",
                                "--exclude '*'",
                                paste0("--include '*/filter/", seqsender$sample_id, "*_filtered_R[12].fastq.gz'"),
                                paste0("--include '*/ivar_consensus/", passed_fasta_files, "*.consensus.fa'"))

aws_s3_cecret_download <- system2("ssh", c("-tt", ec2_hostname,
                                           shQuote(paste(c(cecret_file_download_command,
                                                           ec2_upload_tmp_fp,
                                                           cecret_file_download_param), collapse = " "),
                                                   type = "sh")),
                                  stdout = TRUE, stderr = TRUE)

ssh_command_check(aws_s3_cecret_download)

create_concat_consensus <- system2("ssh", c("-tt", ec2_hostname,
                                            shQuote(paste0("mkdir -p ", dirname(consensus_fasta_fp), "; ",
                                                           "sed -E 's/^N+|N+$|Consensus_|_S[0-9]*.consensus_threshold.*//g' ",
                                                           ec2_upload_tmp_fp, "/processed_cecret/ivar_consensus/* > ",
                                                           consensus_fasta_fp, ";"), type = "sh")),
                                   stdout = TRUE, stderr = TRUE)

dir.create(here("upload", "fasta"))

download_consensus <- system2("scp", c(paste0(ec2_hostname, ":", consensus_fasta_fp),
                                       here("upload", "fasta/")),
                              stdout = TRUE, stderr = TRUE)

ssh_command_check(c(create_concat_consensus, download_consensus))

warning(simpleWarning(
  paste("\n Before continuing, upload", basename(consensus_fasta_fp), "in", here("upload", "fasta/"),
        "to https://clades.nextstrain.org/\n",
        "(Cancel this script to do this and then rerun this chunk when file passes)\n",
        "Check that the FASTA sequences are acceptable (no novel early stop codons, novel truncated spike proteins, or novel frameshifts)\n",
        "If any sequences are low quality, delete them from the FASTA file and reupload the file as", consensus_fasta_fp,
        "and continue with the submission")))
Sys.sleep(20)

upload_seqsender_files <- system2("scp", c(seqsender_meta_fp, config2upload,
                                           paste0(ec2_hostname, ":", ec2_upload_tmp_fp, "/seqsender")))
                                  
ssh_command_check(upload_seqsender_files)

ssh_seqsender_cmd("prep")

# check the seqsender file for GISAID accession numbers
# if the seqsender file already has legit GISAID accession numbers, don't resubmit because GISAID already has these samples
if(all(grepl("^EPI_ISL_0$", seqsender$gisaid_accession)) | all(is.na(seqsender$gisaid_accession))) {
  
  # clear these GISAID log files if exist
  file.remove(local_gs_log)
  
  # submit files to gisaid
  # covCLI is a program that can be downloaded from gisaid.org; add it to $PATH
  run_in_terminal(paste("ssh -tt", ec2_hostname,
                        shQuote(paste("covCLI", "upload",
                                      "--clientid", gs_client_id,
                                      "--username", gisaid_username,
                                      "--metadata", paste0(ec2_upload_tmp_fp, "/gisaid/", project_name, "_gisaid.csv"),
                                      "--fasta", paste0(ec2_upload_tmp_fp, "/gisaid/",project_name, "_gisaid.fsa"),
                                      "--frameshift", "catch_novel",
                                      "--log", ec2_gs_log), type = "sh")))
  
  rstudioapi::executeCommand('activateConsole')
  
  download_gisaid_load <- system2("mkdir", c("-p", paste0(here("gisaid"), ";"),
                                             "scp", c(paste0(ec2_hostname, ":", ec2_gs_log), local_gs_log)))
  
  ssh_command_check(download_gisaid_load)
  
}

# read in the GISAID log file
# if upload was successful, grab the GISAID accessions for the SRA and GenBank submissions
read_gisaid_accessions <- read_csv(local_gs_log, col_names = c("code", "msg", "timestamp"))

gisaid_errors <- read_gisaid_accessions %>%
  filter(grepl("error", code, ignore.case = TRUE))

if(nrow(gisaid_errors) > 0) {
  stop(simpleError(paste0("Something went wrong! GISAID upload failed. Did you use the wrong credentials?\n",
                          "This error may also occur if these samples have been already uploaded\n",
                          "Depending on following error message, you may be able to just rerun this chunk to resubmit:\n",
                          gisaid_errors)))
}

gisaid_success <- read_gisaid_accessions %>%
  filter(grepl("epi_isl_id", code))

if(nrow(gisaid_success) != nrow(seqsender)) {
  stop(simpleError("Some GISAID samples failed to upload."))
}
  
gisaid_accessions <- gisaid_success %>%
  mutate(msg = gsub("^msg: ", "", msg)) %>%
  separate(msg, into = c("gisaid_name", "gisaid_accession"), sep = "; ", extra = "merge") %>%
  mutate(genbank_note = paste0("GISAID virus name: ", gisaid_name, "; GISAID accession: ", gisaid_accession)) %>%
  select(gisaid_name, gisaid_accession, genbank_note)
  
if(!test_upload) {
  #if there is a connection error for the real submission, start appending to the file, instead of rewriting it each time. Find a way to keep the column name the same
  gisaid_accessions %>%
    write_csv(here("gisaid", paste0(project_name, "_gisaid_accessions.csv")))
}

#rewrite the seqsender file with the gisaid accession numbers and remove the old prepared files
seqsender %>%
  select(-c(gisaid_accession, genbank_note)) %>%
  merge(gisaid_accessions, by = "gisaid_name", all.x = TRUE) %>%
  write_tsv(seqsender_meta_fp)

reupload_seqsender_file <- system2("scp", c(seqsender_meta_fp, paste0(ec2_hostname, ":", ec2_seqsender_meta_fp)))

ssh_command_check(reupload_seqsender_file)

### submit files to biosample and sra
ssh_seqsender_cmd("submit")

### submit files to genbank
ssh_seqsender_cmd("genbank")

```
